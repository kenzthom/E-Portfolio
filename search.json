[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Education\n\nThe University of British Columbia Vancouver Masters of Geomatics for Environmental Management (MGEM)\nCurrent\nConcentration: ArcGIS Pro, QGIS, Remote Sensing, R, Python, PostgreSQL, Database Management\nThe University of British Columbia Okanagan B.A. Major in Geography\nMay 2023\nConcentration: Earth Sciences, ESRI ArcGIS Products\n\n\n\nTeaching Assistantships\n\nThe University of British Columbia Geomatics for Natural Resource Management Laboratory Teaching Assistant\nCurrent\nSupport undergraduate students in applied geomatics labs, including GIS, remote sensing, and spatial data analysis for natural resource management. Provided technical guidance on workflows and troubleshooting to reinforce geospatial concepts and analytical accuracy. Assist with grading, lab evaluation, and instructional support to ensure consistency with course learning objectives.\nThe University of British Columbia Earth Systems Laboratory Teaching Assistant\nAugust 2020 – December 2020\nCo-created engaging lesson plans that integrated real-world environmental issues. Provided individualized guidance to students during labs to deepen their understanding of scientific concepts and procedures. Managed assignment and exam grading with accuracy and consistency\n\n\n\nRelevant Work Experience\n\nChartwell Resource Group Ltd. Jr. Forestry Field Technician\nAugust 2024 – August 2025\nCollected, analyzed, and mapped data on tree stands to manage forest vegetation health, growth, and natural resources. Designed and established GPS-marked harvest block boundaries and access roads. Utilized ArcGIS Field Maps, QGIS and RoadEng for effective data visualizations that support informed decision making. Supported the execution of hydro-based capital projects.  \nThe City of Vancouver Assistant Wildlife Technician\nApril 2023 – December 2023\nAssisted in developing and implementing the Park Board’s Canada Goose Management Plan. Conducted field surveys to monitor population, habitat use, and behavior. 2 Leveraged data collected in ArcGIS FieldMaps to inform management strategies. Collaborated with local stakeholders to ensure effective wildlife management.\n\n\n\nReports\n\n(Eventually…) GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada\n\n\n\nAwards & Honors\n\nDean’s List, The University of British Columbia\nA designation that recognizes exceptional academic achievements. Awarded to students that receive an average of 85% or higher on at least 27 credits per session.\nAchieved September 2018 – May 2023\nDeputy Vice-Chancellor Scholarship, The University of British Columbia\nAwarded to the top 10% of returning domestic students based on academic achievement in the previous year.\nAchieved September 2018 – May 2023\n\n\n\nInstitutional Service\n\nThe Hive Bouldering Instructor\nAugust 2022 – December 2023\nTaught beginner through advanced bouldering techniques to diverse groups, fostering skill development, safety awareness, and a supportive environment. Designed tailored training programs, accommodating various skill levels and learning styles.\n\n\n\nProfessional Certifications\n\nOFA1 – First Aid & CPR/AED Level\nAST1 – Avalanche Skills Training & Safety Theory\nENV-050 – Approved Work Practices for Managing Riparian Vegetation\nBCH ENV-041 – Wildlife Awareness\nBCH ENV-028 – Heritage and Archaeology Awareness\nBCH ENV-148 – Invasive Species Awareness"
  },
  {
    "objectID": "projects/solar_suitability.html",
    "href": "projects/solar_suitability.html",
    "title": "Capstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada",
    "section": "",
    "text": "This project evaluates potential locations for utility-scale (1MW+) solar farm development using a GIS-based multi-criteria decision analysis (MCDA). The study integrates environmental, technical, and economic considerations to identify areas most suitable for solar farm development. Data incorperated into the mask layer includes:\nData incorporated as suitability criterion in the Analytically Hierarchical Process (AHP):\nUsing spatial analysis and weighted overlay techniques, I produced a suitability model that highlights optimal locations while minimizing environmental and land-use conflicts. All processing was completed in R at a spatial resolution of 30m in the BC Environmental Albers CRS (EPSG:3005). Upsampling and re-projection has been undergone for web-publishing.\nThe project demonstrates the application of geospatial tools to renewable energy planning and supports data-driven decision-making for sustainable infrastructure development."
  },
  {
    "objectID": "projects/solar_suitability.html#interactive-suitability-map",
    "href": "projects/solar_suitability.html#interactive-suitability-map",
    "title": "Capstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada",
    "section": "Interactive Suitability Map",
    "text": "Interactive Suitability Map\nSuitability is ranked on a 1-5 scale, with 1 being least suitable and 5 being very suitable.\nThe mask layer represents unsuitable land where solar farm installations are not feasible or permitted; it is comprised of data layers mentioned about.\n\n\nterra 1.8.60"
  },
  {
    "objectID": "projects/fire_analysis.html",
    "href": "projects/fire_analysis.html",
    "title": "Analysis of Fire Burn Severity and Post-Fire Vegetation Recovery with Landsat",
    "section": "",
    "text": "This project quantified the burn severity of the Prouton Lakes fire and examined the recovery and re-establishment of vegetation in the years following the fire using Landsat 8 OLI imagery.\nCheck out some code snippets:\n\n\n\n\n\n\nView step 1: Basic data exploration, cleaning, and filtering\n\n\n\n\n\n#read in data\nraw_fire &lt;- sf::st_read(\".../H_FIRE_PLY_polygon.shp\")\n\n#drop geom\nfire &lt;- st_drop_geometry(raw_fire)\n\n#(1)what was the number of fires and total land area burned (in hectares) in 2017?\n#filter year\nfire_summary_2017 &lt;- fire %&gt;%\n  filter(FIRE_YEAR == 2017) %&gt;%\n  summarise(number_of_fires = n(),total_area_burned_ha = sum(SIZE_HA, na.rm = TRUE))\nfire_summary_2017\n\n#(2)what is the ID and burned area (in hectares) of the three largest fires recorded in 2017\nfire_largest &lt;- fire %&gt;%\n  slice_max(SIZE_HA, n = 3) %&gt;%\n  summarise(SIZE_HA, FIRE_NO)\nfire_largest\n  \n#(3)how much land area was burned by the Prouton Lakes fire (ID C30870)  \nfire_prouton &lt;- fire %&gt;%\n  filter(FIRE_NO == \"C30870\") %&gt;%\n  summarise(SIZE_HA, FIRE_NO)\nfire_prouton\n\n#(4)create a barplot showing the total area burned per year in BC. Each bar should be colored by fire cause\ntotal_burn &lt;- fire %&gt;%\n  group_by(FIRE_YEAR) %&gt;%\n  summarise(total_burn = sum(SIZE_HA, na.rm = TRUE), FIRE_CAUSE)\ntotal_burn\n\n#plot it\nggplot(total_burn, aes(x = FIRE_YEAR, y = total_burn, fill = FIRE_CAUSE)) +\n  geom_bar(stat = \"identity\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +\n  scale_y_continuous(labels = label_comma()) + \n  labs(\n  title = \"Total Forest Fire Burn Area Per Year in BC\",\n  y = \"Burn Area (ha)\",\n  x = \"Year\",\n  fill = \"Fire Cause\")\n\n\n\n\n\n\n\n\n\nView step 2: Pre-processing Level-2 products and calculating vegetation indices\n\n\n\n\n\n#(1)for each L2 product, put each surface reflectance band (Band 1 to Band 7) in the same raster object\n\n#read in directory as list\ndirlist &lt;- list.dirs(\"data/Landsat 8 OLI_TIRS C2 L2\", full.names = TRUE, recursive = FALSE)\ndirlist[1:5]\n\n#create list to store all tifs\nbands &lt;- list() \n#for loop to read in all files from directory matching pattern\nfor (i in seq_along(dirlist)) {\n  tif_files &lt;- list.files(\n    dirlist[i],\n    pattern = \"SR_B[1-7]\\\\.TIF$\",\n    full.names = TRUE,\n    recursive = TRUE\n  )\n  #order them 1-7\n  tif_files &lt;- tif_files[order(tif_files)]\n  #store as rast object\n  bands[[i]] &lt;- rast(tif_files)\n}\nbands[1:5] #list of SR rasters with bands 1-7 grouped\n\n#(2)mask pixels that do not have the value 21824 (clear conditions) in the QA_PIXEL layers\n\n#load in QA_PIXELS\nqa_files &lt;- list()\nfor (i in seq_along(dirlist)) {\n  qa_list &lt;- list.files(\n    dirlist[i], \n    pattern = \"QA_PIXEL\\\\.TIF$\", \n    full.names = TRUE, \n    recursive = TRUE\n  )\n  #store as rast object\n  qa_files[[i]] &lt;- rast(qa_list)\n}\nqa_files[1:5] #list of QA rasters\n\n#create function to mask band raster using QA raster\nmask_fun &lt;- function(band_rast, qa_rast) {\n  good &lt;- qa_rast == 21824 \n  masked &lt;- terra::mask(band_rast, good, maskvalues = FALSE) #like inverse\n  return(masked)\n}\n\n#use function in mapply to iterate over list\nmasked_bands &lt;- mapply(\n  mask_fun,\n  band_rast = bands,\n  qa_rast = qa_files,\n  SIMPLIFY = FALSE\n)\nmasked_bands\n\n#(3)crop the multi-layer raster to the Prouton Lakes fire extent\n#isolate Prouton Lakes\nprouton_extent &lt;- raw_fire %&gt;%\n  filter(FIRE_NO == \"C30870\") \n#prouton_extent &lt;- st_geometry(prouton_extent)\nplot(prouton_extent)\n\n#transform polygon to raster CRS\nprouton_extent_proj &lt;- st_transform(prouton_extent, crs(masked_bands[[1]]))\n\n#save cropped rasters to SR folder\ncropped_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_SR\")\n\n#get basenames\nproduct_ids &lt;- basename(dirlist)\n\nfor (i in seq_along(masked_bands)) {\n  in_rasts &lt;- masked_bands[[i]]\n  cropped &lt;- crop(in_rasts, prouton_extent_proj)\n  names(cropped) &lt;- names(in_rasts)\n  #save to correct subfolder\n  cropped_file &lt;- file.path(cropped_output, paste0(product_ids[i], \"_SR.tif\"))\n  writeRaster(cropped, filename = cropped_file, overwrite = TRUE)\n}\n\n#list all cropped rasters\ncropped_files &lt;- list.files(cropped_output, pattern = \"\\\\.tif$\", full.names = TRUE)\ncropped_files\n\n#read each raster into a list\nmasked_bands_prouton &lt;- lapply(cropped_files, function(f) terra::rast(f))\n\n#check first raster to make sure it worked\nnlyr(masked_bands_prouton[[1]])\nnames(masked_bands_prouton[[1]])\nplot(masked_bands_prouton[[1]])\n\n#(4)calculate NDVI for each cropped and masked raster\nndvi_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_NDVI\")\nndvi_list &lt;- vector(\"list\", length(masked_bands_prouton))\n\n#create function\nndvi_calc &lt;- function(rast, product) {\n  red &lt;- rast[[4]]\n  nir &lt;- rast[[5]]\n  ndvi &lt;- (nir - red) / (nir + red)\n  ndvi_file &lt;- file.path(ndvi_output, paste0(product, \"_NDVI.tif\"))\n  writeRaster(ndvi, filename = ndvi_file, overwrite = TRUE)\n  \n  return(ndvi)\n}\n\n#loop through all cropped+masked rasters\nfor (i in seq_along(masked_bands_prouton)) {\n  rast &lt;- masked_bands_prouton[[i]]\n  product_id &lt;- product_ids[i]\n  ndvi_list[[i]] &lt;- ndvi_calc(rast, product_id)\n}\n\n#(5)calculate NBR for each cropped and masked raster\nnbr_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_NBR\")\nnbr_list &lt;- vector(\"list\", length(masked_bands_prouton))\n\n#create function\nnbr_calc &lt;- function(rast, product) {\n  nir &lt;- rast[[5]]\n  swir2 &lt;- rast[[7]]\n  nbr &lt;- (nir - swir2) / (nir + swir2)\n  nbr_file &lt;- file.path(nbr_output, paste0(product, \"_NBR.tif\"))\n  writeRaster(nbr, filename = nbr_file, overwrite = TRUE)\n  \n  return(nbr)\n}\n\n#loop through all cropped+masked rasters\nfor (i in seq_along(masked_bands_prouton)) {\n  rast &lt;- masked_bands_prouton[[i]]\n  product_id &lt;- product_ids[i]\n  nbr_list[[i]] &lt;- nbr_calc(rast, product_id)\n}\n\n#(6)plot TCC of area before and after fire\nsr_files &lt;- list.files(\"output/LC08_L2SP_048023_SR\", pattern = \"_SR.tif$\", full.names = TRUE)\n\n#find july 7 2015\nbefore_fire &lt;- sr_files[grepl(\"20150707\", sr_files)]\n\n#find july 15 2018\nafter_fire &lt;- sr_files[grepl(\"20180715\", sr_files)]\n\n#load as spatrast\nbefore_fire_rast &lt;- rast(before_fire)\nafter_fire_rast &lt;- rast(after_fire)\n\n#plot side by side\npar(mfrow = c(1,2))\nterra::plotRGB(before_fire_rast, r=4, g=3, b=2, \n               stretch = \"lin\",\n               main = \"Before Fire\")\nterra::plotRGB(after_fire_rast, r=4, g=3, b=2,\n               stretch = \"lin\",\n               main = \"Before Fire\")\n\n\n\n\n\n\n\n\n\nView step 3: Create yearly composites of NDVI and NBR\n\n\n\n\n\n#(1)get only NDVI rasts in July and August\nndvi_files &lt;- list.files(\"output/LC08_L2SP_048023_NDVI\", pattern=\"_NDVI.tif$\", full.names = TRUE)\n\n#extract basename\nndvi_names &lt;- basename(ndvi_files)\n\n#extract date section of file name\ndate_extract_ndvi &lt;- str_extract(ndvi_names, \"\\\\d{8}\") #first chunk of 8 numbers \nndvi_dates &lt;- as.Date(date_extract_ndvi, format=\"%Y%m%d\")\n\n#filter by July and August\njuly_aug_idx_ndvi &lt;- format(ndvi_dates, \"%m\") %in% c(\"07\", \"08\")\njuly_aug_ndvi &lt;- ndvi_files[july_aug_idx_ndvi]\n\n#get corresponding years for July/August images\nndvi_years &lt;- format(ndvi_dates[july_aug_idx_ndvi], \"%Y\") #all years (includes repeats)\nunique_years_ndvi &lt;- sort(unique(ndvi_years))  #only unique years (no repeats)\nunique_years_ndvi\n\n#check\njuly_aug_ndvi\nndvi_years\nunique_years_ndvi #9 different years\n\n#(2)create yearly composites of average NDVI\nndvi_per_year &lt;- lapply(unique_years_ndvi, function(y) {\n  files_ndvi &lt;- july_aug_ndvi[ndvi_years == y]\n  year_stack_ndvi &lt;- rast(files_ndvi)\n  app(year_stack_ndvi, fun = mean, na.rm = TRUE)\n})\nndvi_per_year\n\n#same for NBR\nnbr_files &lt;- list.files(\"output/LC08_L2SP_048023_NBR\", pattern=\"_NBR.tif$\", full.names = TRUE)\n\n#extract basename\nnbr_names &lt;- basename(nbr_files)\n\n#extract date section\ndate_extract_nbr &lt;- str_extract(nbr_names, \"\\\\d{8}\")\nnbr_dates &lt;- as.Date(date_extract_nbr, format=\"%Y%m%d\")\n\n#filter by July and August\njuly_aug_idx_nbr &lt;- format(nbr_dates, \"%m\") %in% c(\"07\", \"08\")\njuly_aug_nbr &lt;- nbr_files[july_aug_idx_nbr]\n\n#get corresponding years for July/August images\nnbr_years &lt;- format(nbr_dates[july_aug_idx_nbr], \"%Y\")\nunique_years_nbr &lt;- sort(unique(nbr_years))\n\n#check\njuly_aug_nbr\nnbr_years\nunique_years_nbr\n\n#assign years as the names\n#names(nbr_per_year) &lt;- unique_years_nbr\n\n#(3)create yearly composites of average NBR\nnbr_per_year &lt;- lapply(unique_years_nbr, function(y) {\n  files_nbr &lt;- july_aug_nbr[nbr_years == y]\n  year_stack_nbr &lt;- rast(files_nbr)\n  app(year_stack_nbr, fun = mean, na.rm = TRUE)\n})\nnbr_per_year\n\n#(4)calculate average NDVI of all pixels overlaid by PL fire, for each year in the time series\n#assign years as the rast names\nnames(ndvi_per_year) &lt;- unique_years_ndvi \n\nprouton_vect &lt;- vect(prouton_extent_proj)\nndvi_fire_avg &lt;- lapply(ndvi_per_year, function(r) {\n  masked &lt;- mask(r, prouton_vect)       \n  mean(values(masked), na.rm = TRUE)   \n})\n\n# convert to a data.frame to view\nndvi_fire_avg_df &lt;- data.frame(\n  year = names(ndvi_per_year),\n  avg_ndvi = unlist(ndvi_fire_avg)\n)\nndvi_fire_avg_df\n\n#NaN for 2016? check to see if any NDVI pixels within PL extent \nr2016 &lt;- ndvi_per_year[[\"2016\"]]\nvals_raw &lt;- terra::extract(r2016, prouton_vect)\nsummary(vals_raw)\n\n#plot average NDVI across the PL fire area through time\nggplot(ndvi_fire_avg_df, (aes( x = year, y =avg_ndvi, group = 1))) +\n  geom_line() +\n  geom_point() \n\n#plot visually\nndvi_stack &lt;- rast(ndvi_per_year)\nplot(ndvi_stack)\n \n\n\n\n\n\n\n\n\n\nView step 4: Classify burn severity\n\n\n\n\n\n#(1)calculate average NBR of all pixels overlaid by PL fire, for each year in the time series\n#prouton_vect &lt;- vect(prouton_extent_proj)\n#nbr_fire_avg &lt;- lapply(nbr_per_year, function(r) {\n  #masked &lt;- mask(r, prouton_vect)       #mask to fire area\n  #mean(values(masked), na.rm = TRUE)    #calculate average NDVI in PL fire area\n#})\n\n# convert to a data.frame to view\n#nbr_fire_avg_df &lt;- data.frame(\n  #year = names(nbr_per_year),\n  #avg_nbr = unlist(nbr_fire_avg)\n#)\n#nbr_fire_avg_df\n\n#(2)seperate pre-fire and post-fire \n#remember nbr_per_year = list of nbr mean per year within PL area\npre_fire_nbr &lt;- nbr_per_year[[3]]\npost_fire_nbr &lt;- nbr_per_year[[6]]\n  \n#(3)calculate dNBR\ndnbr &lt;- pre_fire_nbr - post_fire_nbr\nplot(dnbr)\n\n#(4)reclassify using table provided \nm &lt;- c(-0.2, 0.15, 0,\n       0.15, 0.25, 1,\n       0.25, 0.3, 2,\n       0.3, 1, 3)\ndnbr_mat &lt;- matrix(m, ncol = 3, byrow = TRUE)\nburn_severity &lt;- terra::classify(x = dnbr, rcl = dnbr_mat, include.lowest = TRUE, right = TRUE)\n\n#make categorical\nburn_severity &lt;- as.factor(burn_severity)\n\n#add levels\nlevels(burn_severity) &lt;- data.frame(id = c(0, 1, 2, 3), label = c(\"Unburned\", \"Low Severity\", \"Medium Severity\", \"High Severity\"))\n\n#(5)plot dnbr rast with PL fire extent on top\nplot(burn_severity, col = c(\"darkgreen\",\"yellow\",\"orange\",\"red\"), main=\"Burn Severity\")\n\n#convert SpatVecter to sf\nprouton_sf &lt;- st_as_sf(prouton_extent_proj)\n\n#extract geom\nprouton_geom &lt;- st_geometry(prouton_sf)\n\n#overlay\nplot(prouton_geom, add = TRUE, border = \"black\")\n\n\n\n\n\n\n\n\n\nView step 5: Quantity post-fire vegetation recovery\n\n\n\n\n\n#(1)dnbr raster to polygons\nburn_polys &lt;- terra::as.polygons(burn_severity, dissolve = TRUE)\n#check it out #prettyyy \nbp_sf &lt;- st_as_sf(burn_polys)\nplot(bp_sf)\n\n#(2)retrieve categorical labels assigned \nburn_polys$burn_class &lt;- levels(burn_severity)[[1]]$label\nbp_df &lt;- as.data.frame(burn_polys)\nbp_df\n\n#extract years from grand list \nndvi_rasters &lt;- ndvi_per_year[c(\"2018\", \"2019\", \"2020\", \"2021\")]\n\n#make list to store extract\nndvi_extract_list &lt;- list()\n\n#loop through to assign burn class to each poly\nfor (bs in 1:nrow(burn_polys)) {\n  poly &lt;- burn_polys[bs, ]       \n  burn_class_val &lt;- poly$burn_class[1]     \n  \n  #loop through to extract ndvi values per bs class\n  for (i in seq_along(ndvi_rasters)) {\n    \n    rast_obj &lt;- ndvi_rasters[[i]]\n    yr &lt;- names(ndvi_rasters)[i]\n    ex &lt;- terra::extract(rast_obj, poly, method = \"simple\", bind = TRUE)\n    #add burn class to extraction and assign burn class values to extracted\n    ex$burn_class &lt;- burn_class_val\n    #add and assign year\n    ex$year &lt;- yr\n    #store in list\n    ndvi_extract_list &lt;- c(ndvi_extract_list, list(ex))\n  }\n}\n#(4)make into dataframe\nndvi_per_bs &lt;- bind_rows(ndvi_extract_list)\n\n#change mean to ndvi (name stored is spatrast list)\nndvi_per_bs &lt;- ndvi_per_bs %&gt;%\n  rename(ndvi = mean)\n\n#(5)plot ndvi composite of each year \nndvi_years &lt;- list(\n  \"2018\" = ndvi_per_year[[\"2018\"]],\n  \"2019\" = ndvi_per_year[[\"2019\"]],\n  \"2020\" = ndvi_per_year[[\"2020\"]],\n  \"2021\" = ndvi_per_year[[\"2021\"]]\n)\n\n#set plot layout\npar(mfrow = c(2, 2)) \n#loop over each year to plot\nfor (yr in names(ndvi_years)) {\n  plot(\n  ndvi_years[[yr]],\n  main = paste(\"NDVI\", yr),   \n  range = c(0, 0.5),           \n  axes = TRUE\n  )\n}\n \n#(6)boxplot\n#make ordered so burn class plots unburned to high burn\nndvi_per_bs$burn_class &lt;- factor(ndvi_per_bs$burn_class, levels = c(\"Unburned\", \"Low Severity\", \"Medium Severity\", \"High Severity\"), ordered = TRUE)\n\nggplot(ndvi_per_bs, aes(x=year, y=ndvi, fill=burn_class)) + \n  geom_boxplot(position = position_dodge()) +\n  labs(fill = \"Burn Severity\") +\n  scale_fill_manual(values = c(\"green\", \"yellow\", \"orange\", \"red\"))\n\n\n\n\n\nResults"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mackenzie Thomson",
    "section": "",
    "text": "Hi, I’m Mackenzie Thomson!\nI hold a Bachelor’s degree in Geography from the University of British Columbia and am currently pursuing a Master’s in Geomatics for Environmental Management (MGEM) under UBC’s Faculty of Forestry. I’m passionate about applying geospatial technologies to better understand and manage our changing environments. I have a background in the forestry industry as a field technician, where I gained experience in field data collection and forest tenure management across British Columbia. Through the MGEM program, I’m expanding my skills in spatial modelling, remote sensing, and geospatial data analysis to address complex environmental challenges. Currently, I’m developing a model to map solar photovoltaic (PV) suitability across BC, integrating environmental, climate, and infrastructure data to support sustainable energy planning – check it out in the ‘Content & Deliverables’ tab!"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "contact.html#quarto",
    "href": "contact.html#quarto",
    "title": "Contact",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "contact.html#running-code",
    "href": "contact.html#running-code",
    "title": "Contact",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Content & Deliverables",
    "section": "",
    "text": "Here you can find a collection of my work throughout the MGEM program. Click on a card to explore the projects and interactive results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Fire Burn Severity and Post-Fire Vegetation Recovery with Landsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCapstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "map_gallery.html",
    "href": "map_gallery.html",
    "title": "Map Gallery",
    "section": "",
    "text": "Terrain and Riparian Management Area Analysis\nThis map visualizes the Nahmint watershed and riparian management areas. This analysis mapped the stream network using a DEM and extracted stream characteristics to quantify riparian reserve and management zones buffers.\n\n\n\n\n\n\n\n\n\n\n\nSalmon Stream Network Analysis\nThis hydrology based analysis applied network topology to evaluate a capability model of salmon habitat along stream segments using linear referencing. This allowed reachable upstream salmon habitat to be visualized and quantified.\n\n\n\n\n\n\n\n\n\n\n\nSpatial Interpolation and Visualization of LiDAR Data\nThis layout provides a side-by-side comparison of different spatial interpolation algorithms. Zonal statistics present differences between elevation and slope rasters produced with Spline, Nearest Neighbour, and Kriging.\n\n\n\n\n\n\n\n\n\n\n\nManual Digitization Accuracy Assessment\nThis map represents an accuracy assessment comparing manually digitized building footprints to reference data. Kart was utilized for spatial version control.\n\n\n\n\n\n\n\n\n\n\n\nLeast Cost Path Analysis\nThis analysis determines the most efficient routes for Grizzly Bears across a complex landscape, accounting for ‘costs’ such as steep terrain, land cover, and road crossings.\n\n\n\n\n\n\n\n\n\n\n\nCartographic Modelling of Old Growth Forest Inventories\nA spatial assessment of old-growth forest patches. This map compares the percent of old growth forest, derived from VRI, to provincial targets. It highlights conservation priorities based on forest age and fragmentation metrics."
  },
  {
    "objectID": "projects/individual_tree_seg.html",
    "href": "projects/individual_tree_seg.html",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "",
    "text": "This analysis utilized the LidR package to test two general methods of Individual Tree Segmentation. Point cloud normalization and filtering was completed beforehand using a point cloud derived DEM."
  },
  {
    "objectID": "projects/individual_tree_seg.html#method-1",
    "href": "projects/individual_tree_seg.html#method-1",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Method 1",
    "text": "Method 1\nPoint Cloud: Segmentation was based solely on the normalized point cloud data. Li et al., 2012 (Li2012) algorithm was used.\nplot_1_seg &lt;- segment_trees(mkrf_plot_1, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_1_seg, color = \"treeID\")\n\nplot_2_seg &lt;- segment_trees(mkrf_plot_2, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_2_seg, color = \"treeID\")\n\nplot_3_seg &lt;- segment_trees(mkrf_plot_3, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_3_seg, color = \"treeID\")\n\nplot_4_seg &lt;- segment_trees(mkrf_plot_4, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_4_seg, color = \"treeID\")"
  },
  {
    "objectID": "projects/individual_tree_seg.html#results",
    "href": "projects/individual_tree_seg.html#results",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Results",
    "text": "Results\n\n\n\n\n\n\nPlot 1\n\n\n\n\n\n\n\nPlot 2\n\n\n\n\n\n\n\n\n\nPlot 3\n\n\n\n\n\n\n\nPlot 4"
  },
  {
    "objectID": "projects/individual_tree_seg.html#method-2",
    "href": "projects/individual_tree_seg.html#method-2",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Method 2",
    "text": "Method 2\nCanopy Height Model (CHM): Segmentation is based on a CHM using the tree-centric approach. Dalponte and Coomes (dalponte2016) algorithm was used.\nchm_plot1 &lt;- rasterize_canopy(mkrf_plot_1, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops1 &lt;- locate_trees(chm_plot1, lmf(ws = 5, hmin = 2))\nplot(chm_plot1, main = \"Plot 1\")\nplot(tree_tops1, add = TRUE)\n\nchm_plot2 &lt;- rasterize_canopy(mkrf_plot_2, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops2 &lt;- locate_trees(chm_plot2, lmf(ws = 5, hmin = 2))\nplot(chm_plot2, main = \"Plot 2\")\nplot(tree_tops2, add = TRUE)\n\nchm_plot3 &lt;- rasterize_canopy(mkrf_plot_3, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops3 &lt;- locate_trees(chm_plot3, lmf(ws = 5, hmin = 2))\nplot(chm_plot3, main = \"Plot 3\")\nplot(tree_tops3, add = TRUE)\n\nchm_plot4 &lt;- rasterize_canopy(mkrf_plot_4, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops4 &lt;- locate_trees(chm_plot4, lmf(ws = 5, hmin = 2))\nplot(chm_plot4, main = \"Plot 4\")\nplot(tree_tops4, add = TRUE)"
  },
  {
    "objectID": "projects/individual_tree_seg.html#results-1",
    "href": "projects/individual_tree_seg.html#results-1",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Peer-reviewed publications:\nDespite listing them on your resume, it may also be pertinent to create a seperate tab for publications and reports. As your career progresses, this list may become quite long, so be sure to organize things. You may want to point to ‘most recent’ publications, or categorize things by project/topic."
  }
]