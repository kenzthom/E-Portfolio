[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Education\n\nThe University of British Columbia Vancouver Masters of Geomatics for Environmental Management (MGEM)\nCurrent\nConcentration: ArcGIS Pro, QGIS, Remote Sensing, R, Python, PostgreSQL, Database Management\nThe University of British Columbia Okanagan B.A. Major in Geography\nMay 2023\nConcentration: Earth Sciences, ESRI ArcGIS Products\n\n\n\nTeaching Assistantships\n\nThe University of British Columbia Geomatics for Natural Resource Management Laboratory Teaching Assistant\nCurrent\nSupport undergraduate students in applied geomatics labs, including GIS, remote sensing, and spatial data analysis for natural resource management. Provided technical guidance on workflows and troubleshooting to reinforce geospatial concepts and analytical accuracy. Assist with grading, lab evaluation, and instructional support to ensure consistency with course learning objectives.\nThe University of British Columbia Earth Systems Laboratory Teaching Assistant\nAugust 2020 – December 2020\nCo-created engaging lesson plans that integrated real-world environmental issues. Provided individualized guidance to students during labs to deepen their understanding of scientific concepts and procedures. Managed assignment and exam grading with accuracy and consistency\n\n\n\nRelevant Work Experience\n\nChartwell Resource Group Ltd. Jr. Forestry Field Technician\nAugust 2024 – August 2025\nCollected, analyzed, and mapped data on tree stands to manage forest vegetation health, growth, and natural resources. Designed and established GPS-marked harvest block boundaries and access roads. Utilized ArcGIS Field Maps, QGIS and RoadEng for effective data visualizations that support informed decision making. Supported the execution of hydro-based capital projects.  \nThe City of Vancouver Assistant Wildlife Technician\nApril 2023 – December 2023\nAssisted in developing and implementing the Park Board’s Canada Goose Management Plan. Conducted field surveys to monitor population, habitat use, and behavior. 2 Leveraged data collected in ArcGIS FieldMaps to inform management strategies. Collaborated with local stakeholders to ensure effective wildlife management.\n\n\n\nReports\n\n(Eventually…) GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada\n\n\n\nAwards & Honors\n\nDean’s List, The University of British Columbia\nA designation that recognizes exceptional academic achievements. Awarded to students that receive an average of 85% or higher on at least 27 credits per session.\nAchieved September 2018 – May 2023\nDeputy Vice-Chancellor Scholarship, The University of British Columbia\nAwarded to the top 10% of returning domestic students based on academic achievement in the previous year.\nAchieved September 2018 – May 2023\n\n\n\nInstitutional Service\n\nThe Hive Bouldering Instructor\nAugust 2022 – December 2023\nTaught beginner through advanced bouldering techniques to diverse groups, fostering skill development, safety awareness, and a supportive environment. Designed tailored training programs, accommodating various skill levels and learning styles.\n\n\n\nProfessional Certifications\n\nOFA1 – First Aid & CPR/AED Level\nAST1 – Avalanche Skills Training & Safety Theory\nENV-050 – Approved Work Practices for Managing Riparian Vegetation\nBCH ENV-041 – Wildlife Awareness\nBCH ENV-028 – Heritage and Archaeology Awareness\nBCH ENV-148 – Invasive Species Awareness"
  },
  {
    "objectID": "projects/solar_suitability.html",
    "href": "projects/solar_suitability.html",
    "title": "Capstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada",
    "section": "",
    "text": "This project evaluates potential locations for utility-scale (1MW+) solar farm development using a GIS-based multi-criteria decision analysis (MCDA). The study integrates environmental, technical, and economic considerations to identify areas most suitable for solar farm development. Data incorperated into the mask layer includes:\nData incorporated as suitability criterion in the Analytically Hierarchical Process (AHP):\nUsing spatial analysis and weighted overlay techniques, I produced a suitability model that highlights optimal locations while minimizing environmental and land-use conflicts. All processing was completed in R at a spatial resolution of 30m in the BC Environmental Albers CRS (EPSG:3005). Upsampling and re-projection has been undergone for web-publishing.\nThe project demonstrates the application of geospatial tools to renewable energy planning and supports data-driven decision-making for sustainable infrastructure development."
  },
  {
    "objectID": "projects/solar_suitability.html#interactive-suitability-map",
    "href": "projects/solar_suitability.html#interactive-suitability-map",
    "title": "Capstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada",
    "section": "Interactive Suitability Map",
    "text": "Interactive Suitability Map\nSuitability is ranked on a 1-5 scale, with 1 being least suitable and 5 being very suitable.\nThe mask layer represents unsuitable land where solar farm installations are not feasible or permitted; it is comprised of data layers mentioned about.\n\n\nterra 1.8.60"
  },
  {
    "objectID": "projects/fire_analysis.html",
    "href": "projects/fire_analysis.html",
    "title": "Analysis of Fire Burn Severity and Post-Fire Vegetation Recovery with Landsat",
    "section": "",
    "text": "The summer of 2017 was one of the most severe fire seasons in British Columbia, including the Prouton Lakes fire near Williams Lake. This project quantified burn severity and tracked post-fire vegetation recovery using multi-temporal Landsat 8 OLI imagery. I processed large volumes of imagery by developing custom functions and implementing iterative workflows to efficiently calculate burn severity and vegetation indices and monitor landscape-scale recovery patterns over multiple years.\nCheck out some code snippets:\n\n\n\n\n\n\nLandsat imagery processing and vegetation indices function creation\n\n\n\n\n\n#(1)for each L2 product, put each surface reflectance band (Band 1 to Band 7) in the same raster object\n\n#read in directory as list\ndirlist &lt;- list.dirs(\"data/Landsat 8 OLI_TIRS C2 L2\", full.names = TRUE, recursive = FALSE)\ndirlist[1:5]\n\n#create list to store all tifs\nbands &lt;- list() \n#for loop to read in all files from directory matching pattern\nfor (i in seq_along(dirlist)) {\n  tif_files &lt;- list.files(\n    dirlist[i],\n    pattern = \"SR_B[1-7]\\\\.TIF$\",\n    full.names = TRUE,\n    recursive = TRUE\n  )\n  #order them 1-7\n  tif_files &lt;- tif_files[order(tif_files)]\n  #store as rast object\n  bands[[i]] &lt;- rast(tif_files)\n}\nbands[1:5] #list of SR rasters with bands 1-7 grouped\n\n#(2)mask pixels that do not have the value 21824 (clear conditions) in the QA_PIXEL layer using function \n\n#load in QA_PIXELS\nqa_files &lt;- list()\nfor (i in seq_along(dirlist)) {\n  qa_list &lt;- list.files(\n    dirlist[i], \n    pattern = \"QA_PIXEL\\\\.TIF$\", \n    full.names = TRUE, \n    recursive = TRUE\n  )\n  #store as rast object\n  qa_files[[i]] &lt;- rast(qa_list)\n}\nqa_files[1:5] #list of QA rasters\n\n#create function to mask band raster using QA raster\nmask_fun &lt;- function(band_rast, qa_rast) {\n  good &lt;- qa_rast == 21824 \n  masked &lt;- terra::mask(band_rast, good, maskvalues = FALSE) #like inverse\n  return(masked)\n}\n\n#use function in mapply to iterate over list\nmasked_bands &lt;- mapply(\n  mask_fun,\n  band_rast = bands,\n  qa_rast = qa_files,\n  SIMPLIFY = FALSE\n)\nmasked_bands\n\n#(3)crop the multi-layer raster to the Prouton Lakes fire extent\n#isolate Prouton Lakes\nprouton_extent &lt;- raw_fire %&gt;%\n  filter(FIRE_NO == \"C30870\") \n#prouton_extent &lt;- st_geometry(prouton_extent)\nplot(prouton_extent)\n\n#transform polygon to raster CRS\nprouton_extent_proj &lt;- st_transform(prouton_extent, crs(masked_bands[[1]]))\n\n#save cropped rasters to SR folder\ncropped_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_SR\")\n\n#get basenames\nproduct_ids &lt;- basename(dirlist)\n\nfor (i in seq_along(masked_bands)) {\n  in_rasts &lt;- masked_bands[[i]]\n  cropped &lt;- crop(in_rasts, prouton_extent_proj)\n  names(cropped) &lt;- names(in_rasts)\n  #save to correct subfolder\n  cropped_file &lt;- file.path(cropped_output, paste0(product_ids[i], \"_SR.tif\"))\n  writeRaster(cropped, filename = cropped_file, overwrite = TRUE)\n}\n\n#list all cropped rasters\ncropped_files &lt;- list.files(cropped_output, pattern = \"\\\\.tif$\", full.names = TRUE)\ncropped_files\n\n#read each raster into a list\nmasked_bands_prouton &lt;- lapply(cropped_files, function(f) terra::rast(f))\n\n#check first raster to make sure it worked\nnlyr(masked_bands_prouton[[1]])\nnames(masked_bands_prouton[[1]])\nplot(masked_bands_prouton[[1]])\n\n#(4)calculate NDVI for each cropped and masked raster\nndvi_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_NDVI\")\nndvi_list &lt;- vector(\"list\", length(masked_bands_prouton))\n\n#create function\nndvi_calc &lt;- function(rast, product) {\n  red &lt;- rast[[4]]\n  nir &lt;- rast[[5]]\n  ndvi &lt;- (nir - red) / (nir + red)\n  ndvi_file &lt;- file.path(ndvi_output, paste0(product, \"_NDVI.tif\"))\n  writeRaster(ndvi, filename = ndvi_file, overwrite = TRUE)\n  \n  return(ndvi)\n}\n\n#loop through all cropped+masked rasters\nfor (i in seq_along(masked_bands_prouton)) {\n  rast &lt;- masked_bands_prouton[[i]]\n  product_id &lt;- product_ids[i]\n  ndvi_list[[i]] &lt;- ndvi_calc(rast, product_id)\n}\n\n#(5)calculate NBR for each cropped and masked raster\nnbr_output &lt;- file.path(\"output\", \"LC08_L2SP_048023_NBR\")\nnbr_list &lt;- vector(\"list\", length(masked_bands_prouton))\n\n#create function\nnbr_calc &lt;- function(rast, product) {\n  nir &lt;- rast[[5]]\n  swir2 &lt;- rast[[7]]\n  nbr &lt;- (nir - swir2) / (nir + swir2)\n  nbr_file &lt;- file.path(nbr_output, paste0(product, \"_NBR.tif\"))\n  writeRaster(nbr, filename = nbr_file, overwrite = TRUE)\n  \n  return(nbr)\n}\n\n#loop through all cropped+masked rasters\nfor (i in seq_along(masked_bands_prouton)) {\n  rast &lt;- masked_bands_prouton[[i]]\n  product_id &lt;- product_ids[i]\n  nbr_list[[i]] &lt;- nbr_calc(rast, product_id)\n}\n\n#(6)plot TCC of area before and after fire\nsr_files &lt;- list.files(\"output/LC08_L2SP_048023_SR\", pattern = \"_SR.tif$\", full.names = TRUE)\n\n#find july 7 2015\nbefore_fire &lt;- sr_files[grepl(\"20150707\", sr_files)]\n\n#find july 15 2018\nafter_fire &lt;- sr_files[grepl(\"20180715\", sr_files)]\n\n#load as spatrast\nbefore_fire_rast &lt;- rast(before_fire)\nafter_fire_rast &lt;- rast(after_fire)\n\n#plot side by side\npar(mfrow = c(1,2))\nterra::plotRGB(before_fire_rast, r=4, g=3, b=2, \n               stretch = \"lin\",\n               main = \"Before Fire\")\nterra::plotRGB(after_fire_rast, r=4, g=3, b=2,\n               stretch = \"lin\",\n               main = \"Before Fire\")\n\n\n\n\n\n\n\n\n\nNDVI and NBR yearly composite creation\n\n\n\n\n\n#(1)get only NDVI rasts in July and August\nndvi_files &lt;- list.files(\"output/LC08_L2SP_048023_NDVI\", pattern=\"_NDVI.tif$\", full.names = TRUE)\n\n#extract basename\nndvi_names &lt;- basename(ndvi_files)\n\n#extract date section of file name\ndate_extract_ndvi &lt;- str_extract(ndvi_names, \"\\\\d{8}\") #first chunk of 8 numbers \nndvi_dates &lt;- as.Date(date_extract_ndvi, format=\"%Y%m%d\")\n\n#filter by July and August\njuly_aug_idx_ndvi &lt;- format(ndvi_dates, \"%m\") %in% c(\"07\", \"08\")\njuly_aug_ndvi &lt;- ndvi_files[july_aug_idx_ndvi]\n\n#get corresponding years for July/August images\nndvi_years &lt;- format(ndvi_dates[july_aug_idx_ndvi], \"%Y\") #all years (includes repeats)\nunique_years_ndvi &lt;- sort(unique(ndvi_years))  #only unique years (no repeats)\nunique_years_ndvi\n\n#(2)create yearly composites of average NDVI\nndvi_per_year &lt;- lapply(unique_years_ndvi, function(y) {\n  files_ndvi &lt;- july_aug_ndvi[ndvi_years == y]\n  year_stack_ndvi &lt;- rast(files_ndvi)\n  app(year_stack_ndvi, fun = mean, na.rm = TRUE)\n})\nndvi_per_year\n\n#same for NBR\nnbr_files &lt;- list.files(\"output/LC08_L2SP_048023_NBR\", pattern=\"_NBR.tif$\", full.names = TRUE)\n\n#extract basename\nnbr_names &lt;- basename(nbr_files)\n\n#extract date section\ndate_extract_nbr &lt;- str_extract(nbr_names, \"\\\\d{8}\")\nnbr_dates &lt;- as.Date(date_extract_nbr, format=\"%Y%m%d\")\n\n#filter by July and August\njuly_aug_idx_nbr &lt;- format(nbr_dates, \"%m\") %in% c(\"07\", \"08\")\njuly_aug_nbr &lt;- nbr_files[july_aug_idx_nbr]\n\n#get corresponding years for July/August images\nnbr_years &lt;- format(nbr_dates[july_aug_idx_nbr], \"%Y\")\nunique_years_nbr &lt;- sort(unique(nbr_years))\n\n#assign years as the names\n#names(nbr_per_year) &lt;- unique_years_nbr\n\n#(3)create yearly composites of average NBR\nnbr_per_year &lt;- lapply(unique_years_nbr, function(y) {\n  files_nbr &lt;- july_aug_nbr[nbr_years == y]\n  year_stack_nbr &lt;- rast(files_nbr)\n  app(year_stack_nbr, fun = mean, na.rm = TRUE)\n})\nnbr_per_year\n\n#(4)calculate average NDVI of all pixels overlaid by PL fire, for each year in the time series\n#assign years as the rast names\nnames(ndvi_per_year) &lt;- unique_years_ndvi \n\nprouton_vect &lt;- vect(prouton_extent_proj)\nndvi_fire_avg &lt;- lapply(ndvi_per_year, function(r) {\n  masked &lt;- mask(r, prouton_vect)       \n  mean(values(masked), na.rm = TRUE)   \n})\n\n# convert to a data.frame to view\nndvi_fire_avg_df &lt;- data.frame(\n  year = names(ndvi_per_year),\n  avg_ndvi = unlist(ndvi_fire_avg)\n)\nndvi_fire_avg_df\n\n#plot average NDVI across the PL fire area through time\nggplot(ndvi_fire_avg_df, (aes( x = year, y =avg_ndvi, group = 1))) +\n  geom_line() +\n  geom_point() \n\n#plot visually\nndvi_stack &lt;- rast(ndvi_per_year)\nplot(ndvi_stack)\n \n\n\n\n\n\n\n\n\n\nBurn severity classification\n\n\n\n\n\n#(1)calculate average NBR of all pixels overlaid by PL fire, for each year in the time series\n#prouton_vect &lt;- vect(prouton_extent_proj)\n#nbr_fire_avg &lt;- lapply(nbr_per_year, function(r) {\n  #masked &lt;- mask(r, prouton_vect)       #mask to fire area\n  #mean(values(masked), na.rm = TRUE)    #calculate average NDVI in PL fire area\n#})\n\n# convert to a data.frame to view\n#nbr_fire_avg_df &lt;- data.frame(\n  #year = names(nbr_per_year),\n  #avg_nbr = unlist(nbr_fire_avg)\n#)\n#nbr_fire_avg_df\n\n#(2)seperate pre-fire and post-fire \n#remember nbr_per_year = list of nbr mean per year within PL area\npre_fire_nbr &lt;- nbr_per_year[[3]]\npost_fire_nbr &lt;- nbr_per_year[[6]]\n  \n#(3)calculate dNBR\ndnbr &lt;- pre_fire_nbr - post_fire_nbr\nplot(dnbr)\n\n#(4)reclassify using table provided \nm &lt;- c(-0.2, 0.15, 0,\n       0.15, 0.25, 1,\n       0.25, 0.3, 2,\n       0.3, 1, 3)\ndnbr_mat &lt;- matrix(m, ncol = 3, byrow = TRUE)\nburn_severity &lt;- terra::classify(x = dnbr, rcl = dnbr_mat, include.lowest = TRUE, right = TRUE)\n\n#make categorical\nburn_severity &lt;- as.factor(burn_severity)\n\n#add levels\nlevels(burn_severity) &lt;- data.frame(id = c(0, 1, 2, 3), label = c(\"Unburned\", \"Low Severity\", \"Medium Severity\", \"High Severity\"))\n\n#(5)plot dnbr rast with PL fire extent on top\nplot(burn_severity, col = c(\"darkgreen\",\"yellow\",\"orange\",\"red\"), main=\"Burn Severity\")\n\n#convert SpatVecter to sf\nprouton_sf &lt;- st_as_sf(prouton_extent_proj)\n\n#extract geom\nprouton_geom &lt;- st_geometry(prouton_sf)\n\n#overlay\nplot(prouton_geom, add = TRUE, border = \"black\")\n\n\n\n\n\n\n\n\n\nPost-fire vegetation recovery quantification using NDVI\n\n\n\n\n\n#(1)dnbr raster to polygons\nburn_polys &lt;- terra::as.polygons(burn_severity, dissolve = TRUE)\n#check it out #prettyyy \nbp_sf &lt;- st_as_sf(burn_polys)\nplot(bp_sf)\n\n#(2)retrieve categorical labels assigned \nburn_polys$burn_class &lt;- levels(burn_severity)[[1]]$label\nbp_df &lt;- as.data.frame(burn_polys)\nbp_df\n\n#extract years from grand list \nndvi_rasters &lt;- ndvi_per_year[c(\"2018\", \"2019\", \"2020\", \"2021\")]\n\n#make list to store extract\nndvi_extract_list &lt;- list()\n\n#loop through to assign burn class to each poly\nfor (bs in 1:nrow(burn_polys)) {\n  poly &lt;- burn_polys[bs, ]       \n  burn_class_val &lt;- poly$burn_class[1]     \n  \n  #loop through to extract ndvi values per bs class\n  for (i in seq_along(ndvi_rasters)) {\n    \n    rast_obj &lt;- ndvi_rasters[[i]]\n    yr &lt;- names(ndvi_rasters)[i]\n    ex &lt;- terra::extract(rast_obj, poly, method = \"simple\", bind = TRUE)\n    #add burn class to extraction and assign burn class values to extracted\n    ex$burn_class &lt;- burn_class_val\n    #add and assign year\n    ex$year &lt;- yr\n    #store in list\n    ndvi_extract_list &lt;- c(ndvi_extract_list, list(ex))\n  }\n}\n#(4)make into dataframe\nndvi_per_bs &lt;- bind_rows(ndvi_extract_list)\n\n#change mean to ndvi (name stored is spatrast list)\nndvi_per_bs &lt;- ndvi_per_bs %&gt;%\n  rename(ndvi = mean)\n\n#(5)plot ndvi composite of each year \nndvi_years &lt;- list(\n  \"2018\" = ndvi_per_year[[\"2018\"]],\n  \"2019\" = ndvi_per_year[[\"2019\"]],\n  \"2020\" = ndvi_per_year[[\"2020\"]],\n  \"2021\" = ndvi_per_year[[\"2021\"]]\n)\n\n#set plot layout\npar(mfrow = c(2, 2)) \n#loop over each year to plot\nfor (yr in names(ndvi_years)) {\n  plot(\n  ndvi_years[[yr]],\n  main = paste(\"NDVI\", yr),   \n  range = c(0, 0.5),           \n  axes = TRUE\n  )\n}\n \n#(6)boxplot\n#make ordered so burn class plots unburned to high burn\nndvi_per_bs$burn_class &lt;- factor(ndvi_per_bs$burn_class, levels = c(\"Unburned\", \"Low Severity\", \"Medium Severity\", \"High Severity\"), ordered = TRUE)\n\nggplot(ndvi_per_bs, aes(x=year, y=ndvi, fill=burn_class)) + \n  geom_boxplot(position = position_dodge()) +\n  labs(fill = \"Burn Severity\") +\n  scale_fill_manual(values = c(\"green\", \"yellow\", \"orange\", \"red\"))\n\n\n\n\n\nResults\n\n\n\n\nImage 1: Yearly composite of NDVI averaged across July and August in the Prouton Lakes fire area . Pixels with unclear conditions have been masked using Landsats QA Pixel layer.\n\n\n\n\n\n\n\nImage 2: Prouton Lakes fire burn severity classification using bNBR values, considering 2015 as the pre-fire year and 2018 as the post-fire year. dNBR ranges are as followed: -0.2-0.15 are unburned, 0.15-0.25 are low severity, 0.25-0.3 are medium severity, 0.3-1 are high severity.\n\n\n\n\n\n\n\nImage 3: Post fire vegetation recovery in years following the fire. NDVI values were extracted from each burn severity class in order to understand the distribution of vegetation recovery per class."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mackenzie Thomson",
    "section": "",
    "text": "Master’s Student in Geomatics for Environmental Management\nWith a Bachelor’s degree in Geography and hands-on experience as a forestry field technician, I have a deep appreciation for the complexity of British Columbia’s landscapes. Currently pursuing a Master’s in Geomatics for Environmental Management (MGEM) at UBC, I’m turning that field experience into technical expertise. I’m passionate about leveraging geospatial technologies to better understand and manage our changing environments. Through the MGEM program, I’m honing my skills in spatial modeling, remote sensing, and geospatial data analysis to tackle complex environmental challenges."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "I’d love to hear from you!",
    "section": "",
    "text": "I’ll reply as soon as I’m back from the field or trails.\nLinkedIn GitHub Email"
  },
  {
    "objectID": "contact.html#quarto",
    "href": "contact.html#quarto",
    "title": "Contact",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "contact.html#running-code",
    "href": "contact.html#running-code",
    "title": "Contact",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Content & Deliverables",
    "section": "",
    "text": "Here you can find a collection of my work throughout the MGEM program. Click on a card to explore the projects and interactive results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Fire Burn Severity and Post-Fire Vegetation Recovery with Landsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCapstone Project: GIS-Based Site Suitability Analysis for Solar Farms in British Columbia, Canada\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Species at Risk Observations Within Canadian National Parks\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "map_gallery.html",
    "href": "map_gallery.html",
    "title": "Map Gallery",
    "section": "",
    "text": "Terrain and Riparian Management Area Analysis\nThis map visualizes the Nahmint watershed and riparian management areas. This analysis mapped the stream network using a DEM and extracted stream characteristics to quantify riparian reserve and management zones buffers.\n\n\n\n\n\n\n\n\n\n\n\nSalmon Stream Network Analysis\nThis hydrology based analysis applied network topology to evaluate a capability model of salmon habitat along stream segments using linear referencing. This allowed reachable upstream salmon habitat to be visualized and quantified.\n\n\n\n\n\n\n\n\n\n\n\nSpatial Interpolation and Visualization of LiDAR Data\nThis layout provides a side-by-side comparison of different spatial interpolation algorithms. Zonal statistics present differences between elevation and slope rasters produced with Spline, Nearest Neighbour, and Kriging.\n\n\n\n\n\n\n\n\n\n\n\nManual Digitization Accuracy Assessment\nThis map represents an accuracy assessment comparing manually digitized building footprints to reference data. Kart was utilized for spatial version control.\n\n\n\n\n\n\n\n\n\n\n\nLeast Cost Path Analysis\nThis analysis determines the most efficient routes for Grizzly Bears across a complex landscape, accounting for ‘costs’ such as steep terrain, land cover, and road crossings.\n\n\n\n\n\n\n\n\n\n\n\nCartographic Modelling of Old Growth Forest Inventories\nA spatial assessment of old-growth forest patches. This map compares the percent of old growth forest, derived from VRI, to provincial targets. It highlights conservation priorities based on forest age and fragmentation metrics."
  },
  {
    "objectID": "projects/individual_tree_seg.html",
    "href": "projects/individual_tree_seg.html",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "",
    "text": "This analysis utilized the LidR package to test two general methods of Individual Tree Segmentation. Point cloud normalization and filtering was completed beforehand using a point cloud derived DEM."
  },
  {
    "objectID": "projects/individual_tree_seg.html#method-1",
    "href": "projects/individual_tree_seg.html#method-1",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Method 1",
    "text": "Method 1\nPoint Cloud: Segmentation was based solely on the normalized point cloud data. Li et al., 2012 (Li2012) algorithm was used.\n#Plot 1:\nplot_1_seg &lt;- segment_trees(mkrf_plot_1, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_1_seg, color = \"treeID\")\n\n#Plot 2:\nplot_2_seg &lt;- segment_trees(mkrf_plot_2, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_2_seg, color = \"treeID\")\n\n#Plot 3\nplot_3_seg &lt;- segment_trees(mkrf_plot_3, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_3_seg, color = \"treeID\")\n\n#Plot 4\nplot_4_seg &lt;- segment_trees(mkrf_plot_4, li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10))\nplot(plot_4_seg, color = \"treeID\")"
  },
  {
    "objectID": "projects/individual_tree_seg.html#results",
    "href": "projects/individual_tree_seg.html#results",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Results",
    "text": "Results\n\n\n\n\n\n\nPlot 1\n\n\n\n\n\n\n\nPlot 2\n\n\n\n\n\n\n\n\n\nPlot 3\n\n\n\n\n\n\n\nPlot 4"
  },
  {
    "objectID": "projects/individual_tree_seg.html#method-2",
    "href": "projects/individual_tree_seg.html#method-2",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Method 2",
    "text": "Method 2\nCanopy Height Model (CHM): Segmentation is based on a CHM using the tree-centric approach. Dalponte and Coomes (dalponte2016) algorithm was used.\n#Plot 1:\nchm_plot1 &lt;- rasterize_canopy(mkrf_plot_1, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops1 &lt;- locate_trees(chm_plot1, lmf(ws = 5, hmin = 2))\ncrowns_plot1 &lt;- segment_trees(mkrf_plot_1, dalponte2016(chm_plot1, tree_tops1, th_tree = 2, th_seed = 0.45, th_cr = 0.55, max_cr = 10, ID = \"treeID\"))\nplot(crowns_plot1, color = \"treeID\")\n\n#Plot 2:\nchm_plot2 &lt;- rasterize_canopy(mkrf_plot_2, 0.5, pitfree(thresholds = c(0, 10, 20, 30),max_edge = c(0,1), subcircle = 0.2))\ntree_tops2 &lt;- locate_trees(chm_plot2, lmf(ws = 5, hmin = 2))\ncrowns_plot2 &lt;- segment_trees(mkrf_plot_2, dalponte2016(chm_plot2, tree_tops2, th_tree = 2, th_seed = 0.45, th_cr = 0.55, max_cr = 10, ID = \"treeID\"))\nplot(crowns_plot2, color = \"treeID\")\n\n#Plot 3:\nchm_plot3 &lt;- rasterize_canopy(mkrf_plot_3, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops3 &lt;- locate_trees(chm_plot3, lmf(ws = 5, hmin = 2))\ncrowns_plot3 &lt;- segment_trees(mkrf_plot_3, dalponte2016(chm_plot3, tree_tops3, th_tree = 2, th_seed = 0.45, th_cr = 0.55, max_cr = 10, ID = \"treeID\"))\nplot(crowns_plot3, color = \"treeID\")\n\n#Plot 4:\nchm_plot4 &lt;- rasterize_canopy(mkrf_plot_4, 0.5, pitfree(thresholds = c(0, 10, 20, 30), max_edge = c(0,1), subcircle = 0.2))\ntree_tops4 &lt;- locate_trees(chm_plot4, lmf(ws = 5, hmin = 2))\ncrowns_plot4 &lt;- segment_trees(mkrf_plot_4, dalponte2016(chm_plot4, tree_tops4, th_tree = 2, th_seed = 0.45, th_cr = 0.55, max_cr = 10, ID = \"treeID\"))\nplot(crowns_plot4, color = \"treeID\")"
  },
  {
    "objectID": "projects/individual_tree_seg.html#results-1",
    "href": "projects/individual_tree_seg.html#results-1",
    "title": "Individual Tree Segmentation using LiDAR Data from Malcolm Knapp Research Forest",
    "section": "Results",
    "text": "Results\n\n\n\n\n\n\nPlot 1\n\n\n\n\n\n\n\nPlot 2\n\n\n\n\n\n\n\n\n\nPlot 3\n\n\n\n\n\n\n\nPlot 4"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Peer-reviewed publications:\nDespite listing them on your resume, it may also be pertinent to create a seperate tab for publications and reports. As your career progresses, this list may become quite long, so be sure to organize things. You may want to point to ‘most recent’ publications, or categorize things by project/topic."
  },
  {
    "objectID": "projects/python_parks.html",
    "href": "projects/python_parks.html",
    "title": "Investigating Species at Risk Observations Within Canadian National Parks",
    "section": "",
    "text": "Species at risk (SAR), particularly those with specialized habitat requirements, are highly vulnerable to landscape change driven by human activity and development. Protected areas are intended to mitigate these pressures by conserving critical habitats and maintaining biodiversity. However, while national parks encompass a range of ecosystems, certain habitats essential to SAR may be underrepresented within park boundaries and therefore inadequately protected. This national-scale analysis evaluates which SAR occur within Canadian national parks and assesses whether their associated habitats are sufficiently represented. For this study, the analysis focused on terrestrial mammals, with all data processing conducted in Python using Pandas, GeoPandas, and Matplotlib.\nCreated with: Kenzie Stevenson, Asiya Rizva\n\nData\n\nCanadian Provincial Park Polygons\nSAR Registry (as defined under the Species at Risk Act)\nGBIF (Global Biodiversity Information Facility) Species Occurrence Data\n\n\n\nObjective 1: Identify the spatial occurrence of species at risk in Canadian National Parks\n\n\n\n\n\n\nClean SAR data\n\n\n\n\n\n# Filter sar_df to only include terrestrial mammals. This cuts down the time taken for this analysis.\nsar_df_filtered = sar_df[sar_df[\"taxonomic_group\"] == \"Mammals (terrestrial)\"]\n\n# Create list of ALL sar species names from the sar_df_filtered file\nall_species_list = list(sar_df_filtered.iloc[:, 3])\n\n# Remove duplicates from the species list.\ntar_species = list(set(all_species_list))\n\n# Check that the tar species have been kept\nprint(tar_species)\n\n# Inspect the length to get an idea of expected computation time.\nlen(tar_species)\n\n\n\n\n\n\n\n\n\nPull GBIF data\n\n\n\n\n\n# Adapted from Seely https://github.com/subornaa/Geospatial-data-analysis-project-started-kit/blob/main/parks_sar.ipynb\n# Based on code from https://discourse.gbif.org/t/retrieving-inaturalist-observations-for-a-region-observers-with-pygbif/4565\n\nspecies_occurrences = {}\n\n# Adapted into a loop to download observations for each species in our target list.\nfor TARGET_SP in tar_species:\n    # Indicate which species is being downloaded\n    print(f\"\\nDownloading occurrences for {TARGET_SP}...\")\n\n    # Create empty list for results\n    results = []\n    offset = 0\n    # If occurrences are for TARGET_SP, in Canada, have coordinates and no geospatial issues, assign them to out\n    while True:\n        out = occurrences.search(scientificName=TARGET_SP, # this seaches the GBIF database for all observations of the species in the loop.\n                                 country='CA', # this narrows down the scope to Canada\n                                 hasCoordinate=True,\n                                 hasGeospatialIssue=False,\n                                 offset=offset\n                                )\n        # If there are no results of occurrences, break\n        if len(out['results']) == 0:\n            break\n        # Give an indication of progress\n        results.extend(out['results'])\n        offset += len(out['results'])\n        print(f\"Total records downloaded: {len(results)}\")\n\n    # If no reslts, continue\n    if not results:\n        print(f\"---No data found for {TARGET_SP}\")\n        continue\n\n    lat_ls = [results[i]['decimalLatitude'] for i in range(len(results))]\n    lon_ls = [results[i]['decimalLongitude'] for i in range(len(results))]\n\n    # Create dataframe of results for this species.\n    df = pd.DataFrame(results)\n\n    # Append results for this species to the occurrences_gdf\n    occurrences_gdf = gpd.GeoDataFrame(\n        df,\n        geometry=gpd.points_from_xy(df.decimalLongitude, df.decimalLatitude),\n        # Indicate df crs\n        crs=\"EPSG:4326\"\n        # Transform to parks_gdf crs\n    ).to_crs(parks_gdf.crs)\n\n    # Keep only points inside parks using geopandas spatial join with intersects predicate\n    in_parks_gdf = gpd.sjoin(occurrences_gdf, parks_gdf, predicate='intersects')\n\n    # Store results of species occurrences in the parks\n    species_occurrences[TARGET_SP] = in_parks_gdf\n\n    print(f\"---Points inside parks: {len(in_parks_gdf)}\")\n\n\n\n\nVisual Results\n\n\n\nTerrestrial mammals occurrence data plotting within Canadian Parks using GBIF and SAR Registry.\n\n\n\n\n\nObjective 2 Analyze conservation value of the National Parks\n\n\n\n\n\n\nCalculate index that represents conservation value of each park\n\n\n\n\n\n# Create a dataframe with values based on the SARA listing level of each species found in each park \n# These values were subjectively selected and could be adapted based on further research.\n# Higher risk species given a higher weight than lower risk species\n\nrank_value_df = pd.DataFrame({\n    \"sara_status\": [\"Endangered\", \"Threatened\", \"Special Concern\"],\n    \"sara_value\": [7, 3, 1]\n})\n\n# Merge the sar_df with the rank_value_df to have a SARA value for each species\n    # Merge is the geopandas attribute join, as opposed to s.join which is the spatial join\nsar_df_vals = sar_df_filtered.merge(rank_value_df, on=\"sara_status\", how=\"left\")\n\n# Keep only relevant SARA fields\nsara_info = (sar_df_vals[[\"species\", \"sara_status\", \"sara_value\"]])\n\n# Reset index (drop the old index so we don't get duplicate columns)\nall_sp_occ = all_sp_occ.reset_index(drop=True)\n\n# Merge SARA info into occurrences, add SARA_info (all relevant fields) to all occurrences\nall_occ = all_sp_occ.merge(sara_info, on=\"species\", how=\"left\")\n\n# Drop any duplicates of the same species and park combination\nunique_species_per_park = all_occ.drop_duplicates(subset=[\"NAME_E\", \"species\"])\n\n# Counts the number of unique species per park\nsummary = (\n    # Start with DataFrame\n    unique_species_per_park\n    # Group by unique park name and endangered status\n    .groupby([\"NAME_E\", \"sara_status\"])\n    # Count the number of species in each park/sara status category\n    .agg(n_species=(\"species\", \"count\"))\n    .reset_index()\n)\n\nprint(\"National Parks and number of occurring listed species: \\n\", summary)\n\nNational Parks and number of occurring listed species: \n                                                NAME_E      sara_status  \\\n0                     AULAVIK NATIONAL PARK OF CANADA  Special Concern   \n1                   AUYUITTUQ NATIONAL PARK OF CANADA  Special Concern   \n2                       BANFF NATIONAL PARK OF CANADA       Endangered   \n3                       BANFF NATIONAL PARK OF CANADA  Special Concern   \n4       CAPE BRETON HIGHLANDS NATIONAL PARK OF CANADA  Special Concern   \n5                    FORILLON NATIONAL PARK OF CANADA  Special Concern   \n6                       FUNDY NATIONAL PARK OF CANADA       Endangered   \n7        GEORGIAN BAY ISLANDS NATIONAL PARK OF CANADA       Endangered   \n8                     GLACIER NATIONAL PARK OF CANADA  Special Concern   \n9                  GRASSLANDS NATIONAL PARK OF CANADA       Endangered   \n10                 GRASSLANDS NATIONAL PARK OF CANADA  Special Concern   \n11                 GRASSLANDS NATIONAL PARK OF CANADA       Threatened   \n12                 GROS MORNE NATIONAL PARK OF CANADA  Special Concern   \n13       GWAII HAANAS NATIONAL PARK RESERVE OF CANADA       Endangered   \n14       GWAII HAANAS NATIONAL PARK RESERVE OF CANADA  Special Concern   \n15                    IVVAVIK NATIONAL PARK OF CANADA  Special Concern   \n16                     JASPER NATIONAL PARK OF CANADA       Endangered   \n17                     JASPER NATIONAL PARK OF CANADA  Special Concern   \n18                 KEJIMKUJIK NATIONAL PARK OF CANADA       Endangered   \n19                     KLUANE NATIONAL PARK OF CANADA  Special Concern   \n20             KLUANE NATIONAL PARK RESERVE OF CANADA  Special Concern   \n21                   KOOTENAY NATIONAL PARK OF CANADA  Special Concern   \n22              KOUCHIBOUGUAC NATIONAL PARK OF CANADA       Endangered   \n23           MOUNT REVELSTOKE NATIONAL PARK OF CANADA       Endangered   \n24           MOUNT REVELSTOKE NATIONAL PARK OF CANADA  Special Concern   \n25            NAHANNI NATIONAL PARK RESERVE OF CANADA  Special Concern   \n26  NÃÃTSâIHCHâOH NATIONAL PARK RESERVE OF C...  Special Concern   \n27                POINT PELEE NATIONAL PARK OF CANADA       Endangered   \n28                POINT PELEE NATIONAL PARK OF CANADA  Special Concern   \n29              PRINCE ALBERT NATIONAL PARK OF CANADA       Endangered   \n30              PRINCE ALBERT NATIONAL PARK OF CANADA  Special Concern   \n31                 QAUSUITTUQ NATIONAL PARK OF CANADA  Special Concern   \n32               QUTTINIRPAAQ NATIONAL PARK OF CANADA  Special Concern   \n33            RIDING MOUNTAIN NATIONAL PARK OF CANADA  Special Concern   \n34                   SIRMILIK NATIONAL PARK OF CANADA  Special Concern   \n35                 TERRA NOVA NATIONAL PARK OF CANADA  Special Concern   \n36      THAIDENE NENE NATIONAL PARK RESERVE OF CANADA  Special Concern   \n37          TORNGAT MOUNTAINS NATIONAL PARK OF CANADA  Special Concern   \n38              TUKTUT NOGAIT NATIONAL PARK OF CANADA  Special Concern   \n39                     VUNTUT NATIONAL PARK OF CANADA  Special Concern   \n40                     WAPUSK NATIONAL PARK OF CANADA  Special Concern   \n41             WATERTON LAKES NATIONAL PARK OF CANADA       Endangered   \n42             WATERTON LAKES NATIONAL PARK OF CANADA  Special Concern   \n43               WOOD BUFFALO NATIONAL PARK OF CANADA       Endangered   \n44               WOOD BUFFALO NATIONAL PARK OF CANADA  Special Concern   \n45                       YOHO NATIONAL PARK OF CANADA  Special Concern   \n\n    n_species  \n0           1  \n1           2  \n2           1  \n3           3  \n4           1  \n5           1  \n6           1  \n7           1  \n8           1  \n9           1  \n10          1  \n11          1  \n12          1  \n13          1  \n14          1  \n15          4  \n16          1  \n17          3  \n18          1  \n19          3  \n20          3  \n21          2  \n22          1  \n23          1  \n24          1  \n25          3  \n26          2  \n27          1  \n28          1  \n29          1  \n30          1  \n31          2  \n32          1  \n33          1  \n34          1  \n35          1  \n36          2  \n37          2  \n38          2  \n39          2  \n40          2  \n41          1  \n42          2  \n43          1  \n44          2  \n45          2  \n\n\n\n\n\n\n\n\n\nAssign final weighted score to each park\n\n\n\n\n\n# Merge the DataFrames to have SARA_values from rank_value_df\nsummary_with_values = summary.merge(rank_value_df, on=\"sara_status\", how=\"left\")\n\n# Create new column that calculates the final weighted score for each park\n# Weighted score is calculated as the number of species multiplied by the weight of that listing level summed for the park.\nsummary_with_values[\"weighted_score\"] = summary_with_values[\"n_species\"] * summary_with_values[\"sara_value\"]\n\n\n# Create summary table with Park Scores\npark_scores = (\n    # Start with the DataFrame\n    summary_with_values\n    # Group by unique name and weighted score, sum and sort\n    .groupby(\"NAME_E\")[\"weighted_score\"]\n    .sum()\n    .reset_index(name=\"weighted_score\")\n    .sort_values(\"weighted_score\", ascending=False)\n)\n\npark_scores2 = park_scores.copy()\n# Clean up National Park Names\npark_scores2['NAME_E']=park_scores2['NAME_E'].str.replace('NATIONAL PARK OF CANADA', '')\npark_scores2['NAME_E']=park_scores2['NAME_E'].str.replace('NATIONAL PARK RESERVE OF CANADA', '')\n\nprint(\"The top 5 parks with highest conservation value are \\n\", park_scores2.head(5))\n\nThe top 5 parks with highest conservation value are \n              NAME_E  weighted_score\n8       GRASSLANDS               11\n2            BANFF               10\n12          JASPER               10\n34    WOOD BUFFALO                9\n33  WATERTON LAKES                9\n\n\n\n\nVisual Results\n\n\n\n\n\nFinal weighted conservation score for each park, determined by number of species occurrences per park and weight of SAR listing level\n\n\n\n\n\n\nConservation value plotted per Canadian Park with at-risk terrestrial mammals\n\n\n\n\n\n\n\nObjective 3: Identify species with underrepresented habitat in parks\n\n\n\n\n\n\nUse point buffer as indicator of species core habitat\n\n\n\n\n\n# Make sure CRS of two input layers match\nall_sp_occ = all_sp_occ.to_crs(parks_gdf.crs)\n\n# Create 5000 m buffer around each species observation point\n    # We selected a large buffer to capture potential habitat for each species. A large buffer reduces the impact of many occurrences on the percieved habitat size.\n    # In the full analysis, we would utilize available landcover layers, and available range information to indicate what is truly \"available habitat\".\nall_sp_occ['buffer'] = all_sp_occ.geometry.buffer(5000)\n\n# Set buffer as the active geometry column\nall_sp_occ = all_sp_occ.set_geometry('buffer')\n\n# Dissolve buffers so area is not double counted for occurences with overlapping buffers\nbuffers_dissolved = all_sp_occ.dissolve(by='species', as_index = False)\n\n# Intersect dissolved species buffers with parks polygon layer\nbuffers_in_parks = gpd.overlay(buffers_dissolved, parks_gdf, how='intersection')\n\n# Calculate area in km2\nbuffers_in_parks['area_km2'] = buffers_in_parks.geometry.area / 1_000_000\n\n# Create summary table\nspecies_area_summary = (\n    buffers_in_parks\n    .groupby('species')['area_km2']\n    .sum()\n    .reset_index()\n    .sort_values(by='area_km2')\n)\nprint(\"The species with the least area of habitat in the National Parks are: \\n\", species_area_summary)\n\nThe species with the least area of habitat in the National Parks are: \n                    species      area_km2\n8     Perimyotis subflavus     13.054551\n10      Scalopus aquaticus     15.796986\n14            Vulpes velox     21.008782\n6   Myotis septentrionalis     76.354091\n4         Martes americana    127.617918\n11           Taxidea taxus    149.835180\n1              Canis lupus    156.827425\n2     Cynomys ludovicianus    241.326510\n7        Ochotona collaris    496.586602\n5         Myotis lucifugus    834.060104\n13         Ursus maritimus   2595.591930\n3                Gulo gulo   3318.138626\n0              Bison bison   5572.034354\n9        Rangifer tarandus   5856.104859\n12            Ursus arctos  12608.552701\n\n\n\n\n\n\n\n\n\nFurther investigate Banff National Park\n\n\n\n\n\n# Sample of mapping all species habitat in one park\n# Set target park\ntarg_park = \"BANFF NATIONAL PARK OF CANADA\"\n\n# Isolate park boundary\npark_boundary = parks_gdf[parks_gdf[\"NAME_E\"] == targ_park]\n\n# extract just target park habitats\ntarg_buffers = buffers_in_parks[buffers_in_parks[\"NAME_E_2\"] == targ_park]\n\n# Plot the park boundary, the species habitat identified within that park\nfig, ax = plt.subplots(figsize=(12, 12))\npark_boundary.plot(\n    ax=ax,\n    edgecolor='black',\n    facecolor='lightgrey')\ntarg_buffers.plot(\n    ax=ax,\n    column='species',\n    cmap='tab20',\n    legend=True,\n    edgecolor='black',\n    alpha=0.6\n)\n# Add a title for that park\nax.set_title(f\"Species Habitat within {targ_park}\", fontsize=16)\n# Add the basemap\ncx.add_basemap(ax, crs=parks_gdf.crs, source=cx.providers.CartoDB.PositronNoLabels, attribution=\"\")\nax.set_axis_off()\nplt.show()\n\n\n\n\nVisual Results\n\n\n\n\n\nBuffered observations points used as a proxy for habitat representation in Canadian Parks,\n\n\n\n\n\n\nSample of data visualized within Banff National Park"
  },
  {
    "objectID": "contact.html#id-love-to-hear-from-you",
    "href": "contact.html#id-love-to-hear-from-you",
    "title": "Contact",
    "section": "",
    "text": "Name \nEmail \nMessage"
  }
]